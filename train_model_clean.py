import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import pickle
from datetime import datetime

print("=" * 80)
print("CLEAN MODEL TRAINING - ZERO DATA LEAKAGE")
print("=" * 80)
print(f"\nTraining Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

# ============================================================================
# LOAD DATA
# ============================================================================

print("\n" + "=" * 80)
print("LOADING DATA")
print("=" * 80)

train = pd.read_csv('training_data_with_momentum.csv')
test = pd.read_csv('testing_data_with_momentum.csv')

print(f"\n[OK] Training: {len(train)} games (2021-2024)")
print(f"[OK] Testing:  {len(test)} games (2024-2025)")

# ============================================================================
# DEFINE FEATURES
# ============================================================================

print("\n" + "=" * 80)
print("FEATURE SELECTION")
print("=" * 80)

# Core Barttorvik features
barttorvik_features = [
    'adjoe_diff', 'adjde_diff', 'barthag_diff', 
    'rank_diff', 'sos_diff', 'ncsos_diff',
    'efg_pct_diff', 'efgd_pct_diff',
    'tor_diff', 'tord_diff',
    'orb_diff', 'drb_diff',
    'ftr_diff', 'ftrd_diff',
    'twop_pct_diff', 'twopd_pct_diff',
    'threep_pct_diff', 'threepd_pct_diff'
]

# Momentum features
momentum_features = [
    'home_ats_last_5', 'away_ats_last_5', 'ats_diff_last_5',
    'home_ats_last_10', 'away_ats_last_10', 'ats_diff_last_10',
    'home_ats_streak', 'away_ats_streak',
    'home_rest_days', 'away_rest_days',
    'margin_trend', 'recent_opp_strength', 'team_ats_expanding',
    'home_games_played', 'away_games_played', 'early_season'
]

# Style matchup features
style_features = [
    'pace_mismatch', 'combined_pace',
    'three_point_matchup', 'turnover_matchup', 'rebounding_matchup'
]

# Combine all features
all_features = barttorvik_features + momentum_features + style_features

print(f"\n[INFO] Total features: {len(all_features)}")
print(f"  - Barttorvik: {len(barttorvik_features)}")
print(f"  - Momentum:   {len(momentum_features)}")
print(f"  - Style:      {len(style_features)}")

# Check which features exist in the data
available_features = [f for f in all_features if f in train.columns]
missing_features = [f for f in all_features if f not in train.columns]

print(f"\n[OK] Available: {len(available_features)}/{len(all_features)} features")

if missing_features:
    print(f"\n[WARN] Missing {len(missing_features)} features:")
    for feature in missing_features:
        print(f"  - {feature}")
    print("\n[ACTION] Proceeding with available features only")

feature_columns = available_features

# ============================================================================
# PREPARE TRAINING DATA
# ============================================================================

print("\n" + "=" * 80)
print("PREPARING DATA")
print("=" * 80)

# Remove rows with missing features
train_clean = train.dropna(subset=feature_columns + ['home_covered'])
test_clean = test.dropna(subset=feature_columns + ['home_covered'])

print(f"\n[CLEAN] Training: {len(train_clean)}/{len(train)} games ({len(train_clean)/len(train)*100:.1f}%)")
print(f"[CLEAN] Testing:  {len(test_clean)}/{len(test)} games ({len(test_clean)/len(test)*100:.1f}%)")

# Extract features and target
X_train = train_clean[feature_columns]
y_train = train_clean['home_covered']

X_test = test_clean[feature_columns]
y_test = test_clean['home_covered']

print(f"\n[INFO] Training: {X_train.shape[0]} samples, {X_train.shape[1]} features")
print(f"[INFO] Testing:  {X_test.shape[0]} samples, {X_test.shape[1]} features")

# ============================================================================
# NORMALIZE FEATURES
# ============================================================================

print("\n" + "=" * 80)
print("FEATURE NORMALIZATION")
print("=" * 80)

# Identify features that should NOT be normalized (already on 0-1 scale or are ranks)
no_normalize = [
    'home_ats_last_5', 'away_ats_last_5', 'home_ats_last_10', 'away_ats_last_10',
    'recent_opp_strength', 'team_ats_expanding', 'early_season',
    'rank_diff'  # Ranks are already on consistent scale
]

# Features to normalize
normalize_features = [f for f in feature_columns if f not in no_normalize]

print(f"\n[INFO] Normalizing {len(normalize_features)} features")
print(f"[INFO] Leaving {len(no_normalize)} features as-is (already scaled)")

# Fit scaler on training data
scaler = StandardScaler()
X_train_scaled = X_train.copy()
X_test_scaled = X_test.copy()

if len(normalize_features) > 0:
    X_train_scaled[normalize_features] = scaler.fit_transform(X_train[normalize_features])
    X_test_scaled[normalize_features] = scaler.transform(X_test[normalize_features])
    print(f"[OK] Features normalized")

# ============================================================================
# TRAIN MODEL
# ============================================================================

print("\n" + "=" * 80)
print("TRAINING MODEL")
print("=" * 80)

print("\n[INFO] Model: Logistic Regression")
print("[INFO] Penalty: L2 (Ridge)")
print("[INFO] Solver: lbfgs")
print("[INFO] Max iterations: 1000")

model = LogisticRegression(
    penalty='l2',
    C=1.0,
    solver='lbfgs',
    max_iter=1000,
    random_state=42
)

print("\n[TRAIN] Fitting model...")
model.fit(X_train_scaled, y_train)
print("[OK] Model trained successfully")

# ============================================================================
# EVALUATE ON TRAINING SET
# ============================================================================

print("\n" + "=" * 80)
print("TRAINING SET PERFORMANCE")
print("=" * 80)

y_train_pred = model.predict(X_train_scaled)
y_train_proba = model.predict_proba(X_train_scaled)[:, 1]

train_accuracy = accuracy_score(y_train, y_train_pred)
train_baseline = y_train.mean()

print(f"\n[RESULT] Accuracy: {train_accuracy*100:.2f}%")
print(f"[INFO] Baseline (always predict home covers): {train_baseline*100:.2f}%")
print(f"[INFO] Improvement over baseline: {(train_accuracy - train_baseline)*100:.2f}%")

# Calculate ROI
train_clean['pred_home_covers'] = y_train_pred
train_clean['prob_home_covers'] = y_train_proba

# Assuming -110 odds (risk $110 to win $100)
train_clean['bet_result'] = np.where(
    train_clean['pred_home_covers'] == train_clean['home_covered'],
    100,  # Win $100
    -110  # Lose $110
)

train_roi = (train_clean['bet_result'].sum() / (110 * len(train_clean))) * 100

print(f"\n[ROI] Training Set: {train_roi:.2f}%")
print(f"[INFO] Total bets: {len(train_clean)}")
print(f"[INFO] Wins: {(train_clean['bet_result'] > 0).sum()}")
print(f"[INFO] Losses: {(train_clean['bet_result'] < 0).sum()}")

# ============================================================================
# EVALUATE ON TEST SET (2024-2025)
# ============================================================================

print("\n" + "=" * 80)
print("TEST SET PERFORMANCE (2024-2025 SEASON)")
print("=" * 80)

y_test_pred = model.predict(X_test_scaled)
y_test_proba = model.predict_proba(X_test_scaled)[:, 1]

test_accuracy = accuracy_score(y_test, y_test_pred)
test_baseline = y_test.mean()

print(f"\n[RESULT] Accuracy: {test_accuracy*100:.2f}%")
print(f"[INFO] Baseline (always predict home covers): {test_baseline*100:.2f}%")
print(f"[INFO] Improvement over baseline: {(test_accuracy - test_baseline)*100:.2f}%")
print(f"\n[BENCHMARK] Break-even threshold: 52.38% (after -110 juice)")

if test_accuracy > 0.5238:
    edge = (test_accuracy - 0.5238) * 100
    print(f"[SUCCESS] ‚úÖ Model beats break-even by {edge:.2f}%")
else:
    deficit = (0.5238 - test_accuracy) * 100
    print(f"[WARNING] ‚ö†Ô∏è Model is {deficit:.2f}% below break-even")

# Calculate ROI
test_clean['pred_home_covers'] = y_test_pred
test_clean['prob_home_covers'] = y_test_proba

test_clean['bet_result'] = np.where(
    test_clean['pred_home_covers'] == test_clean['home_covered'],
    100,
    -110
)

test_roi = (test_clean['bet_result'].sum() / (110 * len(test_clean))) * 100

print(f"\n[ROI] Test Set: {test_roi:.2f}%")
print(f"[INFO] Total bets: {len(test_clean)}")
print(f"[INFO] Wins: {(test_clean['bet_result'] > 0).sum()}")
print(f"[INFO] Losses: {(test_clean['bet_result'] < 0).sum()}")

# ============================================================================
# CONFIDENCE-BASED ANALYSIS
# ============================================================================

print("\n" + "=" * 80)
print("CONFIDENCE-BASED PERFORMANCE")
print("=" * 80)

# Define confidence levels
test_clean['confidence'] = np.maximum(y_test_proba, 1 - y_test_proba)
test_clean['confidence_level'] = pd.cut(
    test_clean['confidence'],
    bins=[0, 0.55, 0.70, 1.0],
    labels=['LOW', 'MEDIUM', 'HIGH']
)

print("\nTest Set Performance by Confidence:")
print("-" * 60)

for level in ['HIGH', 'MEDIUM', 'LOW']:
    subset = test_clean[test_clean['confidence_level'] == level]
    if len(subset) > 0:
        accuracy = (subset['pred_home_covers'] == subset['home_covered']).mean()
        roi = (subset['bet_result'].sum() / (110 * len(subset))) * 100
        
        print(f"\n{level} Confidence (prob > {0.70 if level == 'HIGH' else 0.55}):")
        print(f"  Games: {len(subset)}")
        print(f"  Accuracy: {accuracy*100:.2f}%")
        print(f"  ROI: {roi:.2f}%")
        print(f"  Record: {(subset['bet_result'] > 0).sum()}-{(subset['bet_result'] < 0).sum()}")

# ============================================================================
# FEATURE IMPORTANCE
# ============================================================================

print("\n" + "=" * 80)
print("TOP 20 MOST IMPORTANT FEATURES")
print("=" * 80)

# Get feature coefficients
feature_importance = pd.DataFrame({
    'feature': feature_columns,
    'coefficient': model.coef_[0]
})
feature_importance['abs_coefficient'] = abs(feature_importance['coefficient'])
feature_importance = feature_importance.sort_values('abs_coefficient', ascending=False)

print("\n(Positive = favors home team covering, Negative = favors away team)")
print("-" * 60)

for i, row in feature_importance.head(20).iterrows():
    direction = "‚Üí HOME" if row['coefficient'] > 0 else "‚Üê AWAY"
    print(f"{row['feature']:25s} {row['coefficient']:8.4f} {direction}")

# ============================================================================
# SAVE MODEL
# ============================================================================

print("\n" + "=" * 80)
print("SAVING MODEL")
print("=" * 80)

model_data = {
    'model': model,
    'scaler': scaler,
    'feature_columns': feature_columns,
    'normalize_features': normalize_features,
    'no_normalize': no_normalize,
    'train_accuracy': train_accuracy,
    'test_accuracy': test_accuracy,
    'train_roi': train_roi,
    'test_roi': test_roi,
    'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
    'training_games': len(train_clean),
    'testing_games': len(test_clean)
}

model_filename = 'spread_model_clean.pkl'
with open(model_filename, 'wb') as f:
    pickle.dump(model_data, f)

print(f"\n[SAVED] {model_filename}")
print(f"[INFO] Model can be loaded with: pickle.load(open('{model_filename}', 'rb'))")

# ============================================================================
# SUMMARY
# ============================================================================

print("\n" + "=" * 80)
print("TRAINING COMPLETE - SUMMARY")
print("=" * 80)

print(f"\nüìä MODEL PERFORMANCE:")
print(f"   Training Accuracy: {train_accuracy*100:.2f}%")
print(f"   Testing Accuracy:  {test_accuracy*100:.2f}%")
print(f"   Training ROI:      {train_roi:.2f}%")
print(f"   Testing ROI:       {test_roi:.2f}%")

print(f"\nüìà DATA QUALITY:")
print(f"   Training Games: {len(train_clean):,} (2021-2024)")
print(f"   Testing Games:  {len(test_clean):,} (2024-2025)")
print(f"   Features Used:  {len(feature_columns)}")

print(f"\n‚úÖ VERIFICATION:")
print(f"   ‚úì Zero data leakage (train/test completely separate)")
print(f"   ‚úì Proper temporal split (past ‚Üí future)")
print(f"   ‚úì Date-specific stats (no future information)")

if test_accuracy > 0.5238:
    print(f"\nüéØ MODEL STATUS: PROFITABLE")
    print(f"   Edge: {(test_accuracy - 0.5238)*100:.2f}% above break-even")
else:
    print(f"\n‚ö†Ô∏è  MODEL STATUS: NEEDS IMPROVEMENT")
    print(f"   Below break-even by {(0.5238 - test_accuracy)*100:.2f}%")

print("\n" + "=" * 80)
